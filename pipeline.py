# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-A6JI84VsibebcvuZt0yz71QCGfXMhEt

# Project Machine Learning Pipeline - Spam Email Prediction
"""

!pip install tfx

"""# Import Library"""

import tensorflow as tf
from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Trainer, Tuner
from tfx.proto import example_gen_pb2
from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext
from tensorflow.keras import layers # Add this import statement
import os
import pandas as pd

"""## Set Variable"""

PIPELINE_NAME = "nbilasals-pipeline"
SCHEMA_PIPELINE_NAME = "spam-tfdv-schema"

#Directory untuk menyimpan artifact yang akan dihasilkan
PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)

# Path to a SQLite DB file to use as an MLMD storage.
METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')

# Output directory where created models from the pipeline will be exported.
SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)

# from absl import logging
# logging.set_verbosity(logging.INFO)

df = pd.read_csv("data/spam.csv")
df

df.info()

DATA_ROOT = "/content/data"

interactive_context = InteractiveContext(pipeline_root=PIPELINE_ROOT)

"""# Data Ingestion

ExampleGen
"""

output = example_gen_pb2.Output(
    split_config = example_gen_pb2.SplitConfig(splits=[
        example_gen_pb2.SplitConfig.Split(name="train", hash_buckets=8),
        example_gen_pb2.SplitConfig.Split(name="eval", hash_buckets=2)
    ])
)
example_gen = CsvExampleGen(input_base=DATA_ROOT, output_config=output)

"""Pada ExampleGen diatas membagi dataset untuk proses training dan evaluasi menjadi rasio 80:20

Menjalankan komponen ExampleGen menggunakan object InteractiveContext() yang telah kita definisikan sebelumnya.
"""

interactive_context.run(example_gen)

"""# Data Validation

StatisticGen

Komponen memiliki parameter input berupa examples untuk menerima dataset dari komponen ExampleGen. Untuk menampilkan summary statistic yang telah dibuat.
"""

statistics_gen = StatisticsGen(
    examples=example_gen.outputs["examples"]
)


interactive_context.run(statistics_gen)

interactive_context.show(statistics_gen.outputs["statistics"])

"""SchemaGen

SchemaGen berfungsi untuk memperoleh informasi dari feature text dan label
"""

schema_gen = SchemaGen(    statistics=statistics_gen.outputs["statistics"]
)
interactive_context.run(schema_gen)

interactive_context.show(schema_gen.outputs["schema"])

"""SchemaGen menghasilkan dua fitur utama, yaitu **Category** sebagai label yang menentukan apakah teks berupa 'spam' atau 'ham' (bertipe INT), dan **Message** sebagai input teks untuk memprediksi label tersebut (bertipe BYTES). Kedua fitur ini bersifat required untuk memastikan data dapat diproses dengan baik dalam pipeline.

ExampleValidator

Tahap selanjutnya adalah mengidentifikasi anomali pada dataset. Proses ini dilakukan menggunakan komponen ExampleValidator() yang telah disediakan oleh TFX. Komponen ini membutuhkan keluaran dari statistics_gen dan schema_gen sebagai parameter input.
"""

example_validator = ExampleValidator(
    statistics=statistics_gen.outputs['statistics'],
    schema=schema_gen.outputs['schema']
)
interactive_context.run(example_validator)

interactive_context.show(example_validator.outputs['anomalies'])

"""Dapat dilihat data yang akan digunakan tidak ditemukan anomali, sehingga siap untuk digunakan untuk proses pipeline selanjutnya

# Data Preprocessing

Transform

Transform akan menerima inputan berupa module file yang berisi preprocessing function.

Sebelum membuat module, kita perlu mendefinisikan nama dari module tersebut.
"""

TRANSFORM_MODULE_FILE = "spam_transform.py"

"""Selanjutnya, membuat sebuah module dengan kode berikut.


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile {TRANSFORM_MODULE_FILE}
# import tensorflow as tf
# 
# LABEL_KEY = "Category"  # Kolom label
# FEATURE_KEY = "Message"  # Kolom fitur
# 
# def transformed_name(key):
#     """Renaming transformed features"""
#     return key + "_xf"
# 
# def preprocessing_fn(inputs):
#     """
#     Preprocess input features into transformed features
# 
#     Args:
#         inputs: map from feature keys to raw features.
# 
#     Return:
#         outputs: map from feature keys to transformed features.
#     """
#     outputs = {}
#     outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)
#     # Mengubah teks menjadi huruf kecil
#     outputs[transformed_name(FEATURE_KEY)] = tf.strings.lower(inputs[FEATURE_KEY])
# 
#     return outputs
#

"""Kode di atas adalah modul transformasi TFX yang mengubah teks pesan menjadi huruf kecil, lalu menambahkan akhiran `_xf` untuk fitur yang sudah ditransformasi.

Membuat transform yang berisi ExampleGen, SchemaGen dan module transform spam_transform.py
"""

transform  = Transform(
    examples=example_gen.outputs['examples'],
    schema= schema_gen.outputs['schema'],
    module_file=os.path.abspath(TRANSFORM_MODULE_FILE)
)
interactive_context.run(transform)

"""Berdasarkan gambar di atas, dapat dilihat bahwa komponen Transform akan menghasilkan beberapa output mulai dari transform_graph, transformed_examples (transformed data), dll. Keseluruhan output nantinya digunakan untuk melakukan preprocessing terhadap serving set. Hal ini akan membantu kita untuk memastikan preprocessing yang dilakukan pada fase training sama dengan fase deployment sehingga dapat mencegah feature skew.

# Model Development

Membuat spam_trainer.py untuk menyimpan proses train pada module spam_trainer.py
"""

TRAINER_MODULE_FILE = "spam_trainer.py"

"""Membuat proses untuk membuat model machine learning dan training model


"""

# Commented out IPython magic to ensure Python compatibility.
# #Membuat file module spam_trainer.py
# %%writefile {TRAINER_MODULE_FILE}
# 
# #Import library
# import tensorflow as tf
# import tensorflow_transform as tft
# from tensorflow.keras import layers
# import os
# import tensorflow_hub as hub
# from tfx.components.trainer.fn_args_utils import FnArgs
# 
# LABEL_KEY = "Category"
# FEATURE_KEY = "Message"
# 
# #Rename feature yang ditransform
# def transformed_name(key) :
#     return key + "_xf"
# 
# #Load data yang dicompress dalam TFRecord
# def gzip_reader_fn(filenames) :
#     return tf.data.TFRecordDataset(filenames, compression_type = 'GZIP')
# 
# #Membuat transformed_feature dan batch data
# def input_fn(file_pattern, tf_transform_output, num_epochs,
#             batch_size=64)->tf.data.Dataset:
# 
#             transform_feature_spec = (
#                 tf_transform_output.transformed_feature_spec().copy()
#             )
# 
#             dataset = tf.data.experimental.make_batched_features_dataset(
#                 file_pattern = file_pattern,
#                 batch_size = batch_size,
#                 features = transform_feature_spec,
#                 reader = gzip_reader_fn,
#                 num_epochs = num_epochs,
#                 label_key = transformed_name(LABEL_KEY)
#             )
#             return dataset
# 
# #Membuat arsitektur model
# VOCAB_SIZE = 10000
# SEQUENCE_LENGTH = 100
# 
# #Melakukan tokenisasi, dan standarisasi data
# vectorize_layer = layers.TextVectorization(
#     standardize = "lower_and_strip_punctuation",
#     max_tokens = VOCAB_SIZE,
#     output_mode = 'int',
#     output_sequence_length = SEQUENCE_LENGTH
# )
# 
# embedding_dim = 16
# 
# #Membuat model machine learning
# def model_builder() :
#     #Machine Learning Model
#     inputs = tf.keras.Input(shape=(1,), name = transformed_name(FEATURE_KEY), dtype = tf.string)
#     reshaped_narrative = tf.reshape(inputs, [-1])
#     x = vectorize_layer(reshaped_narrative)
#     x = layers.Embedding(VOCAB_SIZE, embedding_dim, name = "embedding")(x)
#     x = layers.GlobalAveragePooling1D()(x)
#     x = layers.Dense(64, activation = "relu")(x)
#     x = layers.Dense(32, activation = "relu")(x)
#     outputs = layers.Dense(1, activation = "sigmoid")(x)
# 
#     model = tf.keras.Model(inputs = inputs, outputs = outputs)
# 
#     #Model compile menggunakan binary_crossentropy, Adam dengan learning_rate 0.01 dan metrics BinaryAccuray
#     model.compile(
#         loss = 'binary_crossentropy',
#         optimizer = tf.keras.optimizers.Adam(0.01),
#         metrics = [tf.keras.metrics.BinaryAccuracy()]
#     )
# 
#     model.summary()
#     return model
# 
# #Melakukan preprocessing pada raw request data yang nanti akan digunakan pada proses deployment
# def _get_serve_tf_examples_fn(model, tf_transform_output) :
# 
#     model.tft_layer = tf_transform_output.transform_features_layer()
# 
#     @tf.function
#     def serve_tf_examples_fn(serialized_tf_examples) :
#         feature_spec = tf_transform_output.raw_feature_spec()
#         feature_spec.pop(LABEL_KEY)
#         parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)
#         transformed_features = model.tft_layer(parsed_features)
#         return model(transformed_features)
#     return serve_tf_examples_fn
# 
# #Melakukan proses training
# def run_fn(fn_args : FnArgs) -> None :
#     log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')
# 
#     tensorboard_callback = tf.keras.callbacks.TensorBoard(
#         log_dir = log_dir, update_freq = 'batch'
#     )
# 
#     #Callback untuk EarlyStopping dan ModelCheckpoint
#     es = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_accuracy', mode = 'max', verbose = 1, patience = 10)
#     mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor = 'val_binary_accuracy', mode = 'max', verbose=1, save_best_only=True)
# 
#     #Load output dari transform data
#     tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)
# 
#     #Membuat batch data
#     train_set = input_fn(fn_args.train_files, tf_transform_output, 10)
#     val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)
#     vectorize_layer.adapt(
#         [j[0].numpy()[0] for j in [
#             i[0][transformed_name(FEATURE_KEY)]
#                 for i in list(train_set)]
#         ]
#     )
# 
#     #Build model
#     model = model_builder()
# 
#     #Training model
#     model.fit(x = train_set,
#             validation_data = val_set,
#             callbacks = [tensorboard_callback, es, mc],
#             steps_per_epoch = 1000,
#             validation_steps = 1000,
#             epochs = 10
#     )
# 
#     signatures = {
#         'serving_default' :
#         _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(
#                                 tf.TensorSpec(
#                                     shape = [None],
#                                     dtype = tf.string,
#                                     name = 'examples'
#                                 )
#         )
#     }
# 
#     #Menyimpan model pada serving_model_dir
#     model.save(fn_args.serving_model_dir, save_format = 'tf', signatures = signatures)

"""Trainer"""

from tfx.proto import trainer_pb2

trainer = Trainer(
    module_file = os.path.abspath(TRAINER_MODULE_FILE),
    examples = transform.outputs['transformed_examples'],
    transform_graph = transform.outputs['transform_graph'],
    schema = schema_gen.outputs['schema'],
    train_args = trainer_pb2.TrainArgs(splits = ['train']),
    eval_args = trainer_pb2.EvalArgs(splits = ['eval'])
)

interactive_context.run(trainer)

"""Resolver

Untuk melakukan analisis dan validasi model, kita perlu menyediakan sebuah baseline model. Hal ini sangat penting terutama ketika kita memiliki lebih dari satu versi model dan ingin membandingkan dua buah versi model yang berbeda. Untuk melakukannya, kita bisa memanfaatkan komponen Resolver().
"""

from tfx.dsl.components.common.resolver import Resolver
from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy
from tfx.types import Channel
from tfx.types.standard_artifacts import Model, ModelBlessing

model_resolver = Resolver(
    strategy_class = LatestBlessedModelStrategy,
    model = Channel(type = Model),
    model_blessing = Channel(type = ModelBlessing)
).with_id('Latest_blessed_model_resolver')

interactive_context.run(model_resolver)

"""Setelah mendefinisikan komponen Resolver, tahap selanjutnya adalah membuat beberapa konfigurasi untuk mengevaluasi model. Konfigurasi ini dibuat menggunakan library TFMA seperti berikut."""

import tensorflow_model_analysis as tfma

eval_config = tfma.EvalConfig(
    model_specs=[tfma.ModelSpec(label_key='Category')],
    slicing_specs=[tfma.SlicingSpec()],
    metrics_specs=[
        tfma.MetricsSpec(metrics=[

            tfma.MetricConfig(class_name='ExampleCount'),
            tfma.MetricConfig(class_name='AUC'),
            tfma.MetricConfig(class_name='FalsePositives'),
            tfma.MetricConfig(class_name='TruePositives'),
            tfma.MetricConfig(class_name='FalseNegatives'),
            tfma.MetricConfig(class_name='TrueNegatives'),
            tfma.MetricConfig(class_name='BinaryAccuracy',
                threshold=tfma.MetricThreshold(
                    value_threshold=tfma.GenericValueThreshold(
                        lower_bound={'value':0.5}),
                    change_threshold=tfma.GenericChangeThreshold(
                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                        absolute={'value':0.0001})
                    )
            )
        ])
    ]
  )

"""Membuat metrik evaluasi yang berisi ExampleCount, AUC, FalsePositives, TruePositives, FalseNegatives, TrueNegatives, dan BinaryAccuray"""

from tfx.components import Evaluator
evaluator = Evaluator(
    examples=example_gen.outputs['examples'],
    model=trainer.outputs['model'],
    baseline_model=model_resolver.outputs['model'],
    eval_config=eval_config)

interactive_context.run(evaluator)

"""Evaluator berisi input ExampleGen, model yang dihasilkan trainer, baseline model dan evaluasi dari model"""

#Membuat visualisasi menggunakan TFMA

eval_result = evaluator.outputs['evaluation'].get()[0].uri
tfma_result = tfma.load_eval_result(eval_result)
tfma.view.render_slicing_metrics(tfma_result)
tfma.addons.fairness.view.widget_view.render_fairness_indicator(
    tfma_result
)

"""# Model Deployment

Pusher

Pusher menerika inputan dari trained model, hasil dari evaluasi dan file path dari model, yang kemudian akan digunakan untuk proses deployment
"""

from tfx.components import Pusher
from tfx.proto import pusher_pb2

pusher = Pusher(
    model = trainer.outputs['model'],
    model_blessing = evaluator.outputs['blessing'],
    push_destination = pusher_pb2.PushDestination(
        filesystem = pusher_pb2.PushDestination.Filesystem(
            base_directory = "serving_model_dir/stress-prediction-model"
        )
    )
)

interactive_context.run(pusher)

import shutil

# Zip the folder
shutil.make_archive('/content/pipelines/nbilasals-pipeline', 'zip', '/content/pipelines/nbilasals-pipeline')

# Download the zipped folder
from google.colab import files
files.download('/content/pipelines/nbilasals-pipeline.zip')

# Zip the folder
shutil.make_archive('/content/serving_model_dir', 'zip', '/content/serving_model_dir')
files.download('/content/serving_model_dir.zip')

!pip freeze > requirements.txt